#!/usr/bin/env python
# coding: utf-8

# In[1]:


import pandas as pd
import seaborn as sns


# In[ ]:


df = pd.read_csv("BetaData.csv")
print(df)


# In[ ]:


df = df.drop(['Donor_Sample'], axis=1)
print(df)


# In[ ]:


#see if there is any missing value
df.isna().sum()


# In[ ]:


#df = df.sum(axis=None, skipna=None)
#print(df)


# In[ ]:


#replace NaN with 0
df = df.fillna(0)
print(df)


# In[ ]:


print(df['is_tumor'].value_counts())
#sns.countplot(df['is_tumor'], label='count')


# In[ ]:


df.dtypes


# In[ ]:


#split dataset into features and target
X = df.iloc[:,0:487177].values
print("X = ", X.shape)
Y = df.iloc[:,487177].values
print("Y = ",Y.shape)


# In[ ]:


#Anova
import sklearn
from sklearn.feature_selection import f_classif
from sklearn.feature_selection import SelectKBest
df1=df.drop(["is_tumor"], axis=1)
print("ANOVA test")
bestfeatures = SelectKBest(score_func=f_classif, k=20)
fit = bestfeatures.fit(df1, Y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(df1.columns)
# concat two dataframes for better visualization
featureScores = pd.concat([dfcolumns, dfscores], axis=1)
featureScores.columns = ['fFeature', 'fScore']  # naming the dataframe columns
print(featureScores.nlargest(20, 'fScore'))


# In[ ]:


#Random forest
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)
print("Random forest")
RF = RandomForestClassifier()
RF.fit(X_train, y_train)
# feature importance
importance = RF.feature_importances_
dfscores = pd.DataFrame(RF.feature_importances_)
dfcolumns = pd.DataFrame(df1.columns)
# concat two dataframes for better visualization
fs = pd.concat([dfcolumns, dfscores], axis=1)
fs.columns = ['rfFeature', 'rfScore']  # naming the dataframe columns
print(fs.nlargest(20, 'rfScore'))


# In[ ]:


#Chi2
from sklearn.feature_selection import chi2
df1=df.drop(["is_tumor"], axis=1)
bestfeatures = SelectKBest(score_func=chi2, k=20)
fit = bestfeatures.fit(df1, Y)
dfscores = pd.DataFrame(fit.scores_)
dfcolumns = pd.DataFrame(df1.columns)
# concat two dataframes for better visualization
featureScores = pd.concat([dfcolumns, dfscores], axis=1)
featureScores.columns = ['chiFeature', 'chiScore']  # naming the dataframe columns
print(featureScores.nlargest(20, 'chiScore'))


# In[ ]:


#split data into train-validation-test
print("train and test split on total dataset", len(X))
X_train0, X_test, y_train0, y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)
print(X_train0.shape)
print(y_train0.shape)
print(X_test.shape)
print(y_test.shape)
print("train and validation split on training dataset", len(X_train0))
X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state = 0)
print(X_train.shape)
print(y_train.shape)
print(X_val.shape)
print(y_val.shape)


# In[ ]:


#feature scaling
from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_val = sc.fit_transform(X_val)
X_test = sc.fit_transform(X_test)


# In[ ]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, cohen_kappa_score, f1_score, roc_auc_score
print("Random forest")
RF = RandomForestClassifier()
RF.fit(X_train, y_train)
y_pred = RF.predict(X_val)
#print(confusion_matrix(y_test, y_pred).ravel())
tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
print("Actual validation dataset")
print(y_val)
print("prediction on the validation dataset")
print(y_pred)
tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
print("tn, fp, fn, tp=", confusion_matrix(y_val, y_pred).ravel())
tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
print("Accuracy: " + str(round((tp + tn) / (tn + fp + tp + fn), 2)))
print("Recall/Sensitivity : " + str(round(tp / (tp + fn), 2)))
print("Specificity : " + str(round(tn / (tn + fp), 2)))
print("F1 score : " + str(round(f1_score(y_val, y_pred))))
print("Cohens kappa : " + str(round(tn / (tn + fp), 2)))
print("ROC AUC : " + str(round(roc_auc_score(y_val, y_pred))))
print("\n")

print("Actual test dataset")
print(y_test)
print("prediction on the test dataset")
y_pred = RF.predict(X_test)
print(y_pred)
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
print("tn, fp, fn, tp=", confusion_matrix(y_test, y_pred).ravel())
print("Accuracy: " + str(round((tp + tn) / (tn + fp + tp + fn), 2)))
print("Recall/Sensitivity : " + str(round(tp / (tp + fn), 2)))
print("Specificity : " + str(round(tn / (tn + fp), 2)))
print("F1 score : " + str(round(f1_score(y_test, y_pred))))
print("Cohens kappa : " + str(round(tn / (tn + fp), 2)))
print("ROC AUC : " + str(round(roc_auc_score(y_test, y_pred))))


# In[ ]:


print(X.shape[1])


# In[ ]:


import numpy as np
from sklearn.feature_selection import SelectFromModel
from sklearn.feature_selection import f_classif
import timeit
start_time = timeit.default_timer()
# code you want to evaluate

# Perform the ANOVA-F Test
fvals, pvals = f_classif(X, Y)
to_remove = pvals >= (.05/ X.shape[1])
X_anova = np.delete(X, obj=to_remove, axis=1)

# Use RandomForest
sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))
sel.fit(X, Y)
# Get selected features
sel_features = sel.get_support()
X_ranForest = np.delete(X, obj=sel_features, axis=1)

print("Total features: ", np.shape(X)[1])
print('Reduced number of features (ANOVA F-Test):', X_anova.shape[1])
print('Reduced number of features (Random Forest):', X_ranForest.shape[1])

#First ANOVA, then RF
fvals, pvals = f_classif(X_anova, Y)
to_remove = pvals >= .05
sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))
sel.fit(X_anova, Y)
# Get selected features
sel_features = sel.get_support()
X_anovaRan = np.delete(X_anova, obj=sel_features, axis=1)
print('Reduced number of features finally(ANOVA, RF):', X_anovaRan.shape[1])
elapsed = timeit.default_timer() - start_time
print(elapsed)


# In[ ]:


#Using ANOVA
#split data into train-validation-test
print("train and test split on total dataset", len(X))
X_train0, X_test, y_train0, y_test = train_test_split(X_anovaRan, Y, test_size=0.2, random_state = 0)
print(X_train0.shape)
print(X_test.shape)
print("train and validation split on training dataset", len(X_train0))
X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state = 0)
print(X_train.shape)
print(X_test.shape)


# In[ ]:


print("Random forest")
RF = RandomForestClassifier()
RF.fit(X_train, y_train)
print("on validation dataset")
y_pred = RF.predict(X_val)
print("tn, fp, fn, tp=", confusion_matrix(y_val, y_pred).ravel())
tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
print("Accuracy: " + str(round((tp + tn) / (tn + fp + tp + fn), 2)))
print("Recall/Sensitivity : " + str(round(tp / (tp + fn), 2)))
print("Specificity : " + str(round(tn / (tn + fp), 2)))
print("F1 score : " + str(round(f1_score(y_val, y_pred))))
print("Cohens kappa : " + str(round(tn / (tn + fp), 2)))
print("ROC AUC : " + str(round(roc_auc_score(y_val, y_pred))))

print("\n")
print("on test dataset")
y_pred = RF.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
print("Accuracy: " + str(round((tp + tn) / (tn + fp + tp + fn), 2)))
print("Recall/Sensitivity : " + str(round(tp / (tp + fn), 2)))
print("Specificity : " + str(round(tn / (tn + fp), 2)))
print("F1 score : " + str(round(f1_score(y_test, y_pred))))
print("Cohens kappa : " + str(round(tn / (tn + fp), 2)))
print("ROC AUC : " + str(round(roc_auc_score(y_test, y_pred))))


# In[ ]:


#Using RF
#split data into train-validation-test
print("train and test split on total dataset", len(X))
X_train0, X_test, y_train0, y_test = train_test_split(X_ranForest, Y, test_size=0.2, random_state = 0)
print(X_train0.shape)
print(X_test.shape)
print("train and validation split on training dataset", len(X_train0))
X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state = 0)
print(X_train.shape)
print(X_test.shape)


# In[ ]:


print("Random forest")
RF = RandomForestClassifier()
RF.fit(X_train, y_train)
y_pred = RF.predict(X_val)
print("tn, fp, fn, tp=", confusion_matrix(y_val, y_pred).ravel())
tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()
print("Accuracy: " + str(round((tp + tn) / (tn + fp + tp + fn), 2)))
print("Recall/Sensitivity : " + str(round(tp / (tp + fn), 2)))
print("Specificity : " + str(round(tn / (tn + fp), 2)))
print("F1 score : " + str(round(f1_score(y_val, y_pred))))
print("Cohens kappa : " + str(round(tn / (tn + fp), 2)))
print("ROC AUC : " + str(round(roc_auc_score(y_val, y_pred))))

print("\n")
print("on test dataset")
y_pred = RF.predict(X_test)
tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()
print("Accuracy: " + str(round((tp + tn) / (tn + fp + tp + fn), 2)))
print("Recall/Sensitivity : " + str(round(tp / (tp + fn), 2)))
print("Specificity : " + str(round(tn / (tn + fp), 2)))
print("F1 score : " + str(round(f1_score(y_test, y_pred))))
print("Cohens kappa : " + str(round(tn / (tn + fp), 2)))
print("ROC AUC : " + str(round(roc_auc_score(y_test, y_pred))))


# In[ ]:





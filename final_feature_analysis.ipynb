{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5addff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9a81709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc5c294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/BetaData_27K_SimpleImpute_Mean_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd9be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[: , 1:]  #deleting 1st column \n",
    "df = df.drop(['Donor_Sample'], axis=1) #deleting this column\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e20c7cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#target = df['is_tumor']\n",
    "df.is_tumor = df.is_tumor.astype(int) #converted is_tumor value float to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926c2501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of markers/ features 24981\n",
      "Number of samples 337\n",
      "1    309\n",
      "0     28\n",
      "Name: is_tumor, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of markers/ features\", len(df.columns)-1)\n",
    "print(\"Number of samples\", len(df))\n",
    "print(df['is_tumor'].value_counts())\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec59b7",
   "metadata": {},
   "source": [
    "Splitting data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec147774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "X =  (337, 24981)\n",
      "Y =  (337,)\n"
     ]
    }
   ],
   "source": [
    "#split dataset into features and target\n",
    "X = df.iloc[:,0:len(df.columns)-1].values\n",
    "print(type(X))\n",
    "print(\"X = \", X.shape)\n",
    "Y = df.iloc[:,len(df.columns)-1].values\n",
    "print(\"Y = \",Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506202a",
   "metadata": {},
   "source": [
    "Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f455bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 24981)\n",
      "(337,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n",
    "#print(X)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "Y_original = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6cbd8",
   "metadata": {},
   "source": [
    "Handling oversampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6ab095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from imblearn.over_sampling import SMOTE\\n\\noversample = SMOTE()\\nX, Y = oversample.fit_resample(X, Y)\\nprint(X.shape)\\nprint(Y.shape)\\n#print(target.shape)'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X, Y = oversample.fit_resample(X, Y)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "#print(target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ec21cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.DataFrame(Y)  #This is the target (Y) after oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bd5845",
   "metadata": {},
   "source": [
    "Reduced features using ANOVA and Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "439c0514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 24981\n",
      "85% of total feature 21234\n",
      "Number of selected features using ANOVA F-test: 3771\n",
      "\n",
      "\n",
      "Only random forest\n",
      "Number of selected features using RF: 496\n",
      "\n",
      "\n",
      "Both ANOVA and random forest\n",
      "Number of selected features using anova and RF: 354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import f_classif\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "print(\"Total number of features:\", X.shape[1])\n",
    "a = round(0.85*(X.shape[1]))\n",
    "print(\"85% of total feature\", a)\n",
    "X_new = SelectKBest(f_classif, k=a).fit_transform(X, Y)\n",
    "#df=pd.DataFrame(X_new)\n",
    "fvals, pvals = f_classif(X_new, Y)\n",
    "to_remove = pvals >= (0.05/X_new.shape[1])\n",
    "X_anova = np.delete(X_new, obj=to_remove, axis=1)\n",
    "print(\"Number of selected features using ANOVA F-test:\", X_anova.shape[1])\n",
    "#print(X_anova)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Only random forest\")\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X, Y)\n",
    "rf_sel_features=sel.get_support()\n",
    "X_rf = np.delete(X, obj=~np.array(rf_sel_features), axis=1)\n",
    "print(\"Number of selected features using RF:\", X_rf.shape[1])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Both ANOVA and random forest\")\n",
    "sel = SelectFromModel(RandomForestClassifier(n_estimators = 100))\n",
    "sel.fit(X_anova, Y)\n",
    "anova_rf_sel_features=sel.get_support()\n",
    "X_anova_rf = np.delete(X_anova, obj=~np.array(anova_rf_sel_features), axis=1)\n",
    "print(\"Number of selected features using anova and RF:\", X_anova_rf.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1593501d",
   "metadata": {},
   "source": [
    "Train-test-validation split on total features (before feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512d7a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test split on total dataset 337\n",
      "train and validation split on training dataset 269\n",
      "Training data: (215, 24981)\n",
      "Validation data (54, 24981)\n",
      "test data (68, 24981)\n"
     ]
    }
   ],
   "source": [
    "#import imblearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, cohen_kappa_score, f1_score, roc_auc_score\n",
    "\n",
    "\n",
    "\n",
    "print(\"train and test split on total dataset\", len(X))\n",
    "X_train0, X_test, y_train0, y_test = train_test_split(X, Y, test_size=0.2, random_state = 0)\n",
    "print(\"train and validation split on training dataset\", len(X_train0))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state = 0)\n",
    "print(\"Training data:\",X_train.shape)\n",
    "print(\"Validation data\", X_val.shape)\n",
    "print(\"test data\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce6d386",
   "metadata": {},
   "source": [
    "Performance of Random forest model on total features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fb7a446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on validation dataset\n",
      "tn, fp, fn, tp= [ 5  1  0 48]\n",
      "Accuracy: 0.98\n",
      "Recall/Sensitivity : 1.0\n",
      "Specificity : 0.83\n",
      "F1 score : 1\n",
      "Cohens kappa : 0.83\n",
      "ROC AUC : 1\n",
      "\n",
      "\n",
      "on test dataset\n",
      "tn, fp, fn, tp= [ 3  1  0 64]\n",
      "Accuracy: 0.99\n",
      "Recall/Sensitivity : 1.0\n",
      "Specificity : 0.75\n",
      "F1 score : 1\n",
      "Cohens kappa : 0.75\n",
      "ROC AUC : 1\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "print(\"on validation dataset\")\n",
    "y_pred = RF.predict(X_val)\n",
    "print(\"tn, fp, fn, tp=\", confusion_matrix(y_val, y_pred).ravel())\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"Accuracy: \" + str(round((tp + tn) / (tn + fp + tp + fn), 2)))\n",
    "print(\"Recall/Sensitivity : \" + str(round(tp / (tp + fn), 2)))\n",
    "print(\"Specificity : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"F1 score : \" + str(round(f1_score(y_val, y_pred))))\n",
    "print(\"Cohens kappa : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"ROC AUC : \" + str(round(roc_auc_score(y_val, y_pred))))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"on test dataset\")\n",
    "y_pred = RF.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"tn, fp, fn, tp=\", confusion_matrix(y_test, y_pred).ravel())\n",
    "print(\"Accuracy: \" + str(round((tp + tn) / (tn + fp + tp + fn), 2)))\n",
    "print(\"Recall/Sensitivity : \" + str(round(tp / (tp + fn), 2)))\n",
    "print(\"Specificity : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"F1 score : \" + str(round(f1_score(y_test, y_pred))))\n",
    "print(\"Cohens kappa : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"ROC AUC : \" + str(round(roc_auc_score(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed253649",
   "metadata": {},
   "source": [
    "Train-test-validation split on selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4752feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train and test split on total dataset 337\n",
      "train and validation split on training dataset 269\n",
      "Training data: (215, 336)\n",
      "Validation data (54, 336)\n",
      "test data (68, 336)\n"
     ]
    }
   ],
   "source": [
    "print(\"train and test split on total dataset\", len(X))\n",
    "X_train0, X_test, y_train0, y_test = train_test_split(X_anova_rf, Y, test_size=0.2, random_state = 0)\n",
    "print(\"train and validation split on training dataset\", len(X_train0))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train0, y_train0, test_size=0.2, random_state = 0)\n",
    "print(\"Training data:\",X_train.shape)\n",
    "print(\"Validation data\", X_val.shape)\n",
    "print(\"test data\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5116044",
   "metadata": {},
   "source": [
    "Performance of Random forest model on reduced features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6cda2e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on validation dataset\n",
      "tn, fp, fn, tp= [ 5  1  0 48]\n",
      "Accuracy: 0.98\n",
      "Recall/Sensitivity : 1.0\n",
      "Specificity : 0.83\n",
      "F1 score : 1\n",
      "Cohens kappa : 0.83\n",
      "ROC AUC : 1\n",
      "\n",
      "\n",
      "on test dataset\n",
      "tn, fp, fn, tp= [ 3  1  0 64]\n",
      "Accuracy: 0.99\n",
      "Recall/Sensitivity : 1.0\n",
      "Specificity : 0.75\n",
      "F1 score : 1\n",
      "Cohens kappa : 0.75\n",
      "ROC AUC : 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, cohen_kappa_score, f1_score, roc_auc_score\n",
    "\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_train, y_train)\n",
    "print(\"on validation dataset\")\n",
    "y_pred = RF.predict(X_val)\n",
    "print(\"tn, fp, fn, tp=\", confusion_matrix(y_val, y_pred).ravel())\n",
    "tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "print(\"Accuracy: \" + str(round((tp + tn) / (tn + fp + tp + fn), 2)))\n",
    "print(\"Recall/Sensitivity : \" + str(round(tp / (tp + fn), 2)))\n",
    "print(\"Specificity : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"F1 score : \" + str(round(f1_score(y_val, y_pred))))\n",
    "print(\"Cohens kappa : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"ROC AUC : \" + str(round(roc_auc_score(y_val, y_pred))))\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"on test dataset\")\n",
    "y_pred = RF.predict(X_test)\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "print(\"tn, fp, fn, tp=\", confusion_matrix(y_test, y_pred).ravel())\n",
    "print(\"Accuracy: \" + str(round((tp + tn) / (tn + fp + tp + fn), 2)))\n",
    "print(\"Recall/Sensitivity : \" + str(round(tp / (tp + fn), 2)))\n",
    "print(\"Specificity : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"F1 score : \" + str(round(f1_score(y_test, y_pred))))\n",
    "print(\"Cohens kappa : \" + str(round(tn / (tn + fp), 2)))\n",
    "print(\"ROC AUC : \" + str(round(roc_auc_score(y_test, y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501462e",
   "metadata": {},
   "source": [
    "Array of selected features to CSV for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d4226ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "anovaRan = pd.DataFrame(X_anova_rf)\n",
    "anovaRan['is_tumor'] = target\n",
    "#print(anovaRan)\n",
    "#anovaRan.to_csv(\"450_sim_anova_RF_woSMOTE.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2711d261",
   "metadata": {},
   "source": [
    "Common features using ANOVA and Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "64c13e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features using ANOVA\n",
      "3771\n",
      "Features using Random forest\n",
      "488\n",
      "Common features of ANOVA and Random forest\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "df1=df.drop([\"is_tumor\"], axis=1)\n",
    "print(\"Features using ANOVA\")\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=X_anova.shape[1])\n",
    "#df1 = pd.DataFrame(X)\n",
    "anova = bestfeatures.fit(df1, Y_original)\n",
    "dfscores = pd.DataFrame(anova.scores_)\n",
    "dfcolumns = pd.DataFrame(df1.columns)\n",
    "# concat two dataframes for better visualization\n",
    "featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "featureScores.columns = ['fFeature', 'fScore']  # naming the dataframe columns\n",
    "best_features = featureScores.nlargest(X_anova.shape[1], 'fScore')\n",
    "#print(best_features)\n",
    "anova_bestfeatures = best_features['fFeature'].tolist()\n",
    "print(len(anova_bestfeatures))\n",
    "\n",
    "print(\"Features using Random forest\")\n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X, Y)\n",
    "# feature importance\n",
    "rf_importance = RF.feature_importances_\n",
    "\n",
    "dfscores = pd.DataFrame(RF.feature_importances_)\n",
    "dfcolumns = pd.DataFrame(df1.columns)\n",
    "# concat two dataframes for better visualization\n",
    "fs = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "fs.columns = ['rfFeature', 'rfScore']  # naming the dataframe columns\n",
    "rf_best_feature = fs.nlargest(X_rf.shape[1], 'rfScore')\n",
    "#print(rf_best_feature)\n",
    "rf_bestfeatures = rf_best_feature['rfFeature'].tolist()\n",
    "print(len(rf_bestfeatures))\n",
    "\n",
    "\n",
    "print(\"Common features of ANOVA and Random forest\")\n",
    "#df_anova = \n",
    "RF = RandomForestClassifier()\n",
    "RF.fit(X_anova, Y)\n",
    "# feature importance\n",
    "importance = RF.feature_importances_\n",
    "dfscores = pd.DataFrame(importance)\n",
    "dfcolumns = pd.DataFrame(df1.columns)\n",
    "# concat two dataframes for better visualization\n",
    "fs = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "fs.columns = ['rfFeature', 'rfScore']  # naming the dataframe columns\n",
    "anovaRF_best_features = fs.nlargest(X_anova_rf.shape[1], 'rfScore')\n",
    "anova_rf_bestfeatures = anovaRF_best_features['rfFeature'].tolist()\n",
    "print(len(anova_rf_bestfeatures))\n",
    "anova_rf_markers = pd.DataFrame (anova_rf_bestfeatures,columns=['Reduced_Markers_AnovaRF'])\n",
    "#anova_rf_markers.to_csv(\"450_sim_AnovaRF_markers_woSMOTE.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
